{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS613 Final Project: Cross-Language Image Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        return pickle.load(fo, encoding='bytes')\n",
    "    \n",
    "def load_cifar10(file_path):\n",
    "    train_data, train_labels = [] , []\n",
    "    for i in range(1,6):\n",
    "        batch = unpickle(f\"{file_path}\\\\data_batch_{i}\")\n",
    "        train_data.append(batch[b'data'])\n",
    "        train_labels.extend(batch[b'labels'])\n",
    "    train_data = np.concatenate(train_data, axis=0)\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    # Load test batch\n",
    "    test_batch = unpickle(f\"{file_path}\\\\test_batch\")\n",
    "    test_data = np.array(test_batch[b'data'])\n",
    "    test_labels = np.array(test_batch[b'labels'])\n",
    "\n",
    "    # Reshape the data to (N, 32, 32, 3)\n",
    "    train_data = train_data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "    test_data = test_data.reshape(-1, 3, 32, 32).transpose(0, 2, 3, 1)\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "# Save data to CSV\n",
    "def save_to_csv(data, labels, file_path):\n",
    "    # Combine labels and data\n",
    "    combined = np.column_stack((labels, data))\n",
    "    np.savetxt(file_path, combined, delimiter=\",\", fmt=\"%f\")\n",
    "    print(f\"Saved {file_path} successfully!\")\n",
    "    \n",
    "# Prepare data\n",
    "def normalize_images(data):\n",
    "    return data / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "def one_hot_encode(labels, num_classes):\n",
    "    one_hot = np.zeros((labels.size, num_classes))\n",
    "    one_hot[np.arange(labels.size),labels] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CIFAR-10 dataset...\n",
      "Preprocessing data...\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "print(\"Loading CIFAR-10 dataset...\")\n",
    "file_path = r\"cifar-10-python\\\\cifar-10-batches-py\"\n",
    "x_train, y_train, x_test, y_test = load_cifar10(file_path)\n",
    "\n",
    "# Preprocess data\n",
    "print(\"Preprocessing data...\")\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test = x_test.reshape(x_test.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to CSV...\n",
      "Saved train.csv successfully!\n",
      "Saved test.csv successfully!\n",
      "CSV files created.\n"
     ]
    }
   ],
   "source": [
    "# Save csv files if needed\n",
    "print(\"Saving to CSV...\")\n",
    "save_to_csv(x_train, y_train, \"train.csv\")\n",
    "save_to_csv(x_test, y_test, \"test.csv\")\n",
    "print(\"CSV files created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "# Normalize data\n",
    "x_train = normalize_images(x_train)\n",
    "x_test = normalize_images(x_test)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = 10\n",
    "y_train = one_hot_encode(y_train, num_classes)\n",
    "y_test = one_hot_encode(y_test, num_classes)\n",
    "\n",
    "# Add biases to X\n",
    "X_train = np.c_[np.ones((x_train.shape[0], 1)), x_train]\n",
    "X_test = np.c_[np.ones((x_test.shape[0], 1)), x_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "def confusion_matrix(y_true, y_pred):\n",
    "    num_classes = y_true.shape[1]\n",
    "    cm = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    y_true_indices = np.argmax(y_true, axis=1)\n",
    "    for t, p in zip(y_true_indices, y_pred):\n",
    "        cm[t, p] += 1\n",
    "    return cm\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    y_true_label = np.argmax(y_true, axis=1)  #Converting one-hot encoded back to label encoded\n",
    "    return np.sum(y_true_label == y_pred) / len(y_true_label)\n",
    "\n",
    "\n",
    "def precision(cm):\n",
    "    precisions = []\n",
    "    for i in range(cm.shape[0]):\n",
    "        tp = cm[i, i]\n",
    "        fp = np.sum(cm[:, i]) - tp\n",
    "        if tp + fp > 0:\n",
    "            precisions.append(tp / (tp + fp))\n",
    "        else:\n",
    "            precisions.append(0)\n",
    "    return np.mean(precisions)\n",
    "\n",
    "def recall(cm):\n",
    "    recalls = []\n",
    "    for i in range(cm.shape[0]):\n",
    "        tp = cm[i, i]\n",
    "        fn = np.sum(cm[i, :]) - tp\n",
    "        if tp + fn > 0:\n",
    "            recalls.append(tp / (tp + fn))\n",
    "        else:\n",
    "            recalls.append(0)\n",
    "    return np.mean(recalls)\n",
    "\n",
    "def f1_score(cm):\n",
    "    precisions = precision(cm)\n",
    "    recalls = recall(cm)\n",
    "    if (precisions + recalls) > 0:\n",
    "        return 2 * (precisions * recalls) / (precisions + recalls) \n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regression:\n",
    "    def __init__(self, learning_rate=0.01, epochs=100):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "        #Weight Initalization\n",
    "        self.num_features = None\n",
    "        self.num_classes = None\n",
    "        self.weights = None\n",
    "\n",
    "        # Initialize lists for tracking losses\n",
    "        self.train_losses = []\n",
    "        self.test_losses = []\n",
    "\n",
    "    # Logistic Regression Functions\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def predictProb(self, X):\n",
    "        y_pred = self.softmax(np.dot(X, self.weights))\n",
    "        return y_pred\n",
    "    \n",
    "    def predict(self, y_pred):\n",
    "        return np.argmax(self.predictProb(y_pred), axis=1)\n",
    "\n",
    "    def log_loss(self, y, y_pred, epsilon=1e-15):\n",
    "        return -np.mean(y * np.log(y_pred + epsilon) + (1 - y) * np.log(1 - y_pred + epsilon))\n",
    "    \n",
    "    def categorical_crossentropy(self, y, y_pred, epsilon=1e-15):\n",
    "        y_pred = np.clip(y_pred, epsilon, 1 - epsilon) \n",
    "        return -np.mean(np.sum(y * np.log(y_pred), axis=1))\n",
    "    \n",
    "    def softmax(self, z):\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))  \n",
    "        return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "    \n",
    "    def gradient_descent(self, X, y, weights, lr):\n",
    "        y_pred = self.softmax(np.dot(X, weights))\n",
    "        error = y_pred - y\n",
    "        gradient = np.dot(X.T, error) / len(y)\n",
    "        return weights - lr * gradient\n",
    "\n",
    "    def fit(self, X_train, y_train, X_test=None, y_test=None):\n",
    "        # Normalize data\n",
    "        self.num_features = X_train.shape[1]\n",
    "        self.num_classes = y_train.shape[1]\n",
    "        self.weights = np.random.normal(loc=0.0, scale=1.0, size=(self.num_features, num_classes)) * 0.01\n",
    "    \n",
    "        for epoch in range(self.epochs):\n",
    "            # Update Weights\n",
    "            self.weights = self.gradient_descent(X_train, y_train, self.weights, self.learning_rate)\n",
    "\n",
    "            train_pred = self.softmax(np.dot(X_train, self.weights))\n",
    "            train_loss = self.categorical_crossentropy(y_train, train_pred)\n",
    "            self.train_losses.append(train_loss)\n",
    "\n",
    "            if X_test is not None and y_test is not None:\n",
    "                test_pred = self.softmax(np.dot(X_test, self.weights))\n",
    "                test_loss = self.categorical_crossentropy(y_test, test_pred)\n",
    "                self.test_losses.append(test_loss)\n",
    "            else:\n",
    "                test_loss = None\n",
    "\n",
    "            # if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch + 1}/{self.epochs}: Train Loss = {train_loss:.4f}, Test Loss = {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500: Train Loss = 2.2908, Test Loss = 2.2914\n",
      "Epoch 2/500: Train Loss = 2.2800, Test Loss = 2.2803\n",
      "Epoch 3/500: Train Loss = 2.2723, Test Loss = 2.2725\n",
      "Epoch 4/500: Train Loss = 2.2651, Test Loss = 2.2654\n",
      "Epoch 5/500: Train Loss = 2.2581, Test Loss = 2.2584\n",
      "Epoch 6/500: Train Loss = 2.2513, Test Loss = 2.2517\n",
      "Epoch 7/500: Train Loss = 2.2448, Test Loss = 2.2453\n",
      "Epoch 8/500: Train Loss = 2.2385, Test Loss = 2.2390\n",
      "Epoch 9/500: Train Loss = 2.2324, Test Loss = 2.2329\n",
      "Epoch 10/500: Train Loss = 2.2265, Test Loss = 2.2270\n",
      "Epoch 11/500: Train Loss = 2.2207, Test Loss = 2.2213\n",
      "Epoch 12/500: Train Loss = 2.2152, Test Loss = 2.2158\n",
      "Epoch 13/500: Train Loss = 2.2098, Test Loss = 2.2105\n",
      "Epoch 14/500: Train Loss = 2.2045, Test Loss = 2.2053\n",
      "Epoch 15/500: Train Loss = 2.1995, Test Loss = 2.2002\n",
      "Epoch 16/500: Train Loss = 2.1946, Test Loss = 2.1953\n",
      "Epoch 17/500: Train Loss = 2.1898, Test Loss = 2.1906\n",
      "Epoch 18/500: Train Loss = 2.1851, Test Loss = 2.1860\n",
      "Epoch 19/500: Train Loss = 2.1806, Test Loss = 2.1815\n",
      "Epoch 20/500: Train Loss = 2.1762, Test Loss = 2.1771\n",
      "Epoch 21/500: Train Loss = 2.1719, Test Loss = 2.1728\n",
      "Epoch 22/500: Train Loss = 2.1678, Test Loss = 2.1687\n",
      "Epoch 23/500: Train Loss = 2.1637, Test Loss = 2.1647\n",
      "Epoch 24/500: Train Loss = 2.1598, Test Loss = 2.1607\n",
      "Epoch 25/500: Train Loss = 2.1560, Test Loss = 2.1569\n",
      "Epoch 26/500: Train Loss = 2.1522, Test Loss = 2.1532\n",
      "Epoch 27/500: Train Loss = 2.1486, Test Loss = 2.1495\n",
      "Epoch 28/500: Train Loss = 2.1450, Test Loss = 2.1460\n",
      "Epoch 29/500: Train Loss = 2.1415, Test Loss = 2.1425\n",
      "Epoch 30/500: Train Loss = 2.1381, Test Loss = 2.1391\n",
      "Epoch 31/500: Train Loss = 2.1348, Test Loss = 2.1358\n",
      "Epoch 32/500: Train Loss = 2.1316, Test Loss = 2.1326\n",
      "Epoch 33/500: Train Loss = 2.1284, Test Loss = 2.1295\n",
      "Epoch 34/500: Train Loss = 2.1253, Test Loss = 2.1264\n",
      "Epoch 35/500: Train Loss = 2.1223, Test Loss = 2.1234\n",
      "Epoch 36/500: Train Loss = 2.1194, Test Loss = 2.1204\n",
      "Epoch 37/500: Train Loss = 2.1165, Test Loss = 2.1175\n",
      "Epoch 38/500: Train Loss = 2.1136, Test Loss = 2.1147\n",
      "Epoch 39/500: Train Loss = 2.1109, Test Loss = 2.1120\n",
      "Epoch 40/500: Train Loss = 2.1082, Test Loss = 2.1093\n",
      "Epoch 41/500: Train Loss = 2.1055, Test Loss = 2.1066\n",
      "Epoch 42/500: Train Loss = 2.1029, Test Loss = 2.1040\n",
      "Epoch 43/500: Train Loss = 2.1004, Test Loss = 2.1015\n",
      "Epoch 44/500: Train Loss = 2.0979, Test Loss = 2.0990\n",
      "Epoch 45/500: Train Loss = 2.0954, Test Loss = 2.0965\n",
      "Epoch 46/500: Train Loss = 2.0930, Test Loss = 2.0941\n",
      "Epoch 47/500: Train Loss = 2.0906, Test Loss = 2.0918\n",
      "Epoch 48/500: Train Loss = 2.0883, Test Loss = 2.0895\n",
      "Epoch 49/500: Train Loss = 2.0861, Test Loss = 2.0872\n",
      "Epoch 50/500: Train Loss = 2.0838, Test Loss = 2.0850\n",
      "Epoch 51/500: Train Loss = 2.0816, Test Loss = 2.0828\n",
      "Epoch 52/500: Train Loss = 2.0795, Test Loss = 2.0806\n",
      "Epoch 53/500: Train Loss = 2.0774, Test Loss = 2.0785\n",
      "Epoch 54/500: Train Loss = 2.0753, Test Loss = 2.0765\n",
      "Epoch 55/500: Train Loss = 2.0733, Test Loss = 2.0744\n",
      "Epoch 56/500: Train Loss = 2.0713, Test Loss = 2.0724\n",
      "Epoch 57/500: Train Loss = 2.0693, Test Loss = 2.0705\n",
      "Epoch 58/500: Train Loss = 2.0674, Test Loss = 2.0685\n",
      "Epoch 59/500: Train Loss = 2.0655, Test Loss = 2.0666\n",
      "Epoch 60/500: Train Loss = 2.0636, Test Loss = 2.0648\n",
      "Epoch 61/500: Train Loss = 2.0617, Test Loss = 2.0629\n",
      "Epoch 62/500: Train Loss = 2.0599, Test Loss = 2.0611\n",
      "Epoch 63/500: Train Loss = 2.0581, Test Loss = 2.0593\n",
      "Epoch 64/500: Train Loss = 2.0564, Test Loss = 2.0576\n",
      "Epoch 65/500: Train Loss = 2.0546, Test Loss = 2.0558\n",
      "Epoch 66/500: Train Loss = 2.0529, Test Loss = 2.0541\n",
      "Epoch 67/500: Train Loss = 2.0513, Test Loss = 2.0525\n",
      "Epoch 68/500: Train Loss = 2.0496, Test Loss = 2.0508\n",
      "Epoch 69/500: Train Loss = 2.0480, Test Loss = 2.0492\n",
      "Epoch 70/500: Train Loss = 2.0464, Test Loss = 2.0476\n",
      "Epoch 71/500: Train Loss = 2.0448, Test Loss = 2.0460\n",
      "Epoch 72/500: Train Loss = 2.0432, Test Loss = 2.0444\n",
      "Epoch 73/500: Train Loss = 2.0417, Test Loss = 2.0429\n",
      "Epoch 74/500: Train Loss = 2.0402, Test Loss = 2.0414\n",
      "Epoch 75/500: Train Loss = 2.0387, Test Loss = 2.0399\n",
      "Epoch 76/500: Train Loss = 2.0372, Test Loss = 2.0384\n",
      "Epoch 77/500: Train Loss = 2.0357, Test Loss = 2.0370\n",
      "Epoch 78/500: Train Loss = 2.0343, Test Loss = 2.0355\n",
      "Epoch 79/500: Train Loss = 2.0329, Test Loss = 2.0341\n",
      "Epoch 80/500: Train Loss = 2.0315, Test Loss = 2.0327\n",
      "Epoch 81/500: Train Loss = 2.0301, Test Loss = 2.0314\n",
      "Epoch 82/500: Train Loss = 2.0287, Test Loss = 2.0300\n",
      "Epoch 83/500: Train Loss = 2.0274, Test Loss = 2.0287\n",
      "Epoch 84/500: Train Loss = 2.0260, Test Loss = 2.0273\n",
      "Epoch 85/500: Train Loss = 2.0247, Test Loss = 2.0260\n",
      "Epoch 86/500: Train Loss = 2.0234, Test Loss = 2.0247\n",
      "Epoch 87/500: Train Loss = 2.0222, Test Loss = 2.0235\n",
      "Epoch 88/500: Train Loss = 2.0209, Test Loss = 2.0222\n",
      "Epoch 89/500: Train Loss = 2.0196, Test Loss = 2.0210\n",
      "Epoch 90/500: Train Loss = 2.0184, Test Loss = 2.0197\n",
      "Epoch 91/500: Train Loss = 2.0172, Test Loss = 2.0185\n",
      "Epoch 92/500: Train Loss = 2.0160, Test Loss = 2.0173\n",
      "Epoch 93/500: Train Loss = 2.0148, Test Loss = 2.0161\n",
      "Epoch 94/500: Train Loss = 2.0136, Test Loss = 2.0149\n",
      "Epoch 95/500: Train Loss = 2.0124, Test Loss = 2.0138\n",
      "Epoch 96/500: Train Loss = 2.0113, Test Loss = 2.0126\n",
      "Epoch 97/500: Train Loss = 2.0102, Test Loss = 2.0115\n",
      "Epoch 98/500: Train Loss = 2.0090, Test Loss = 2.0104\n",
      "Epoch 99/500: Train Loss = 2.0079, Test Loss = 2.0093\n",
      "Epoch 100/500: Train Loss = 2.0068, Test Loss = 2.0082\n",
      "Epoch 101/500: Train Loss = 2.0057, Test Loss = 2.0071\n",
      "Epoch 102/500: Train Loss = 2.0046, Test Loss = 2.0060\n",
      "Epoch 103/500: Train Loss = 2.0036, Test Loss = 2.0050\n",
      "Epoch 104/500: Train Loss = 2.0025, Test Loss = 2.0039\n",
      "Epoch 105/500: Train Loss = 2.0015, Test Loss = 2.0029\n",
      "Epoch 106/500: Train Loss = 2.0004, Test Loss = 2.0019\n",
      "Epoch 107/500: Train Loss = 1.9994, Test Loss = 2.0008\n",
      "Epoch 108/500: Train Loss = 1.9984, Test Loss = 1.9998\n",
      "Epoch 109/500: Train Loss = 1.9974, Test Loss = 1.9988\n",
      "Epoch 110/500: Train Loss = 1.9964, Test Loss = 1.9978\n",
      "Epoch 111/500: Train Loss = 1.9954, Test Loss = 1.9969\n",
      "Epoch 112/500: Train Loss = 1.9945, Test Loss = 1.9959\n",
      "Epoch 113/500: Train Loss = 1.9935, Test Loss = 1.9950\n",
      "Epoch 114/500: Train Loss = 1.9926, Test Loss = 1.9940\n",
      "Epoch 115/500: Train Loss = 1.9916, Test Loss = 1.9931\n",
      "Epoch 116/500: Train Loss = 1.9907, Test Loss = 1.9921\n",
      "Epoch 117/500: Train Loss = 1.9898, Test Loss = 1.9912\n",
      "Epoch 118/500: Train Loss = 1.9888, Test Loss = 1.9903\n",
      "Epoch 119/500: Train Loss = 1.9879, Test Loss = 1.9894\n",
      "Epoch 120/500: Train Loss = 1.9870, Test Loss = 1.9885\n",
      "Epoch 121/500: Train Loss = 1.9861, Test Loss = 1.9876\n",
      "Epoch 122/500: Train Loss = 1.9853, Test Loss = 1.9868\n",
      "Epoch 123/500: Train Loss = 1.9844, Test Loss = 1.9859\n",
      "Epoch 124/500: Train Loss = 1.9835, Test Loss = 1.9850\n",
      "Epoch 125/500: Train Loss = 1.9827, Test Loss = 1.9842\n",
      "Epoch 126/500: Train Loss = 1.9818, Test Loss = 1.9833\n",
      "Epoch 127/500: Train Loss = 1.9810, Test Loss = 1.9825\n",
      "Epoch 128/500: Train Loss = 1.9801, Test Loss = 1.9817\n",
      "Epoch 129/500: Train Loss = 1.9793, Test Loss = 1.9808\n",
      "Epoch 130/500: Train Loss = 1.9785, Test Loss = 1.9800\n",
      "Epoch 131/500: Train Loss = 1.9777, Test Loss = 1.9792\n",
      "Epoch 132/500: Train Loss = 1.9769, Test Loss = 1.9784\n",
      "Epoch 133/500: Train Loss = 1.9761, Test Loss = 1.9776\n",
      "Epoch 134/500: Train Loss = 1.9753, Test Loss = 1.9768\n",
      "Epoch 135/500: Train Loss = 1.9745, Test Loss = 1.9761\n",
      "Epoch 136/500: Train Loss = 1.9737, Test Loss = 1.9753\n",
      "Epoch 137/500: Train Loss = 1.9729, Test Loss = 1.9745\n",
      "Epoch 138/500: Train Loss = 1.9721, Test Loss = 1.9738\n",
      "Epoch 139/500: Train Loss = 1.9714, Test Loss = 1.9730\n",
      "Epoch 140/500: Train Loss = 1.9706, Test Loss = 1.9722\n",
      "Epoch 141/500: Train Loss = 1.9699, Test Loss = 1.9715\n",
      "Epoch 142/500: Train Loss = 1.9691, Test Loss = 1.9708\n",
      "Epoch 143/500: Train Loss = 1.9684, Test Loss = 1.9700\n",
      "Epoch 144/500: Train Loss = 1.9677, Test Loss = 1.9693\n",
      "Epoch 145/500: Train Loss = 1.9669, Test Loss = 1.9686\n",
      "Epoch 146/500: Train Loss = 1.9662, Test Loss = 1.9679\n",
      "Epoch 147/500: Train Loss = 1.9655, Test Loss = 1.9672\n",
      "Epoch 148/500: Train Loss = 1.9648, Test Loss = 1.9665\n",
      "Epoch 149/500: Train Loss = 1.9641, Test Loss = 1.9658\n",
      "Epoch 150/500: Train Loss = 1.9634, Test Loss = 1.9651\n",
      "Epoch 151/500: Train Loss = 1.9627, Test Loss = 1.9644\n",
      "Epoch 152/500: Train Loss = 1.9620, Test Loss = 1.9637\n",
      "Epoch 153/500: Train Loss = 1.9613, Test Loss = 1.9631\n",
      "Epoch 154/500: Train Loss = 1.9607, Test Loss = 1.9624\n",
      "Epoch 155/500: Train Loss = 1.9600, Test Loss = 1.9617\n",
      "Epoch 156/500: Train Loss = 1.9593, Test Loss = 1.9611\n",
      "Epoch 157/500: Train Loss = 1.9587, Test Loss = 1.9604\n",
      "Epoch 158/500: Train Loss = 1.9580, Test Loss = 1.9598\n",
      "Epoch 159/500: Train Loss = 1.9574, Test Loss = 1.9591\n",
      "Epoch 160/500: Train Loss = 1.9567, Test Loss = 1.9585\n",
      "Epoch 161/500: Train Loss = 1.9561, Test Loss = 1.9578\n",
      "Epoch 162/500: Train Loss = 1.9554, Test Loss = 1.9572\n",
      "Epoch 163/500: Train Loss = 1.9548, Test Loss = 1.9566\n",
      "Epoch 164/500: Train Loss = 1.9542, Test Loss = 1.9560\n",
      "Epoch 165/500: Train Loss = 1.9536, Test Loss = 1.9554\n",
      "Epoch 166/500: Train Loss = 1.9529, Test Loss = 1.9547\n",
      "Epoch 167/500: Train Loss = 1.9523, Test Loss = 1.9541\n",
      "Epoch 168/500: Train Loss = 1.9517, Test Loss = 1.9535\n",
      "Epoch 169/500: Train Loss = 1.9511, Test Loss = 1.9529\n",
      "Epoch 170/500: Train Loss = 1.9505, Test Loss = 1.9523\n",
      "Epoch 171/500: Train Loss = 1.9499, Test Loss = 1.9517\n",
      "Epoch 172/500: Train Loss = 1.9493, Test Loss = 1.9512\n",
      "Epoch 173/500: Train Loss = 1.9487, Test Loss = 1.9506\n",
      "Epoch 174/500: Train Loss = 1.9481, Test Loss = 1.9500\n",
      "Epoch 175/500: Train Loss = 1.9476, Test Loss = 1.9494\n",
      "Epoch 176/500: Train Loss = 1.9470, Test Loss = 1.9489\n",
      "Epoch 177/500: Train Loss = 1.9464, Test Loss = 1.9483\n",
      "Epoch 178/500: Train Loss = 1.9458, Test Loss = 1.9477\n",
      "Epoch 179/500: Train Loss = 1.9453, Test Loss = 1.9472\n",
      "Epoch 180/500: Train Loss = 1.9447, Test Loss = 1.9466\n",
      "Epoch 181/500: Train Loss = 1.9441, Test Loss = 1.9461\n",
      "Epoch 182/500: Train Loss = 1.9436, Test Loss = 1.9455\n",
      "Epoch 183/500: Train Loss = 1.9430, Test Loss = 1.9450\n",
      "Epoch 184/500: Train Loss = 1.9425, Test Loss = 1.9444\n",
      "Epoch 185/500: Train Loss = 1.9420, Test Loss = 1.9439\n",
      "Epoch 186/500: Train Loss = 1.9414, Test Loss = 1.9434\n",
      "Epoch 187/500: Train Loss = 1.9409, Test Loss = 1.9428\n",
      "Epoch 188/500: Train Loss = 1.9403, Test Loss = 1.9423\n",
      "Epoch 189/500: Train Loss = 1.9398, Test Loss = 1.9418\n",
      "Epoch 190/500: Train Loss = 1.9393, Test Loss = 1.9413\n",
      "Epoch 191/500: Train Loss = 1.9388, Test Loss = 1.9407\n",
      "Epoch 192/500: Train Loss = 1.9382, Test Loss = 1.9402\n",
      "Epoch 193/500: Train Loss = 1.9377, Test Loss = 1.9397\n",
      "Epoch 194/500: Train Loss = 1.9372, Test Loss = 1.9392\n",
      "Epoch 195/500: Train Loss = 1.9367, Test Loss = 1.9387\n",
      "Epoch 196/500: Train Loss = 1.9362, Test Loss = 1.9382\n",
      "Epoch 197/500: Train Loss = 1.9357, Test Loss = 1.9377\n",
      "Epoch 198/500: Train Loss = 1.9352, Test Loss = 1.9372\n",
      "Epoch 199/500: Train Loss = 1.9347, Test Loss = 1.9367\n",
      "Epoch 200/500: Train Loss = 1.9342, Test Loss = 1.9362\n",
      "Epoch 201/500: Train Loss = 1.9337, Test Loss = 1.9357\n",
      "Epoch 202/500: Train Loss = 1.9332, Test Loss = 1.9353\n",
      "Epoch 203/500: Train Loss = 1.9327, Test Loss = 1.9348\n",
      "Epoch 204/500: Train Loss = 1.9322, Test Loss = 1.9343\n",
      "Epoch 205/500: Train Loss = 1.9318, Test Loss = 1.9338\n",
      "Epoch 206/500: Train Loss = 1.9313, Test Loss = 1.9334\n",
      "Epoch 207/500: Train Loss = 1.9308, Test Loss = 1.9329\n",
      "Epoch 208/500: Train Loss = 1.9303, Test Loss = 1.9324\n",
      "Epoch 209/500: Train Loss = 1.9299, Test Loss = 1.9320\n",
      "Epoch 210/500: Train Loss = 1.9294, Test Loss = 1.9315\n",
      "Epoch 211/500: Train Loss = 1.9289, Test Loss = 1.9311\n",
      "Epoch 212/500: Train Loss = 1.9285, Test Loss = 1.9306\n",
      "Epoch 213/500: Train Loss = 1.9280, Test Loss = 1.9301\n",
      "Epoch 214/500: Train Loss = 1.9275, Test Loss = 1.9297\n",
      "Epoch 215/500: Train Loss = 1.9271, Test Loss = 1.9292\n",
      "Epoch 216/500: Train Loss = 1.9266, Test Loss = 1.9288\n",
      "Epoch 217/500: Train Loss = 1.9262, Test Loss = 1.9284\n",
      "Epoch 218/500: Train Loss = 1.9257, Test Loss = 1.9279\n",
      "Epoch 219/500: Train Loss = 1.9253, Test Loss = 1.9275\n",
      "Epoch 220/500: Train Loss = 1.9249, Test Loss = 1.9271\n",
      "Epoch 221/500: Train Loss = 1.9244, Test Loss = 1.9266\n",
      "Epoch 222/500: Train Loss = 1.9240, Test Loss = 1.9262\n",
      "Epoch 223/500: Train Loss = 1.9236, Test Loss = 1.9258\n",
      "Epoch 224/500: Train Loss = 1.9231, Test Loss = 1.9253\n",
      "Epoch 225/500: Train Loss = 1.9227, Test Loss = 1.9249\n",
      "Epoch 226/500: Train Loss = 1.9223, Test Loss = 1.9245\n",
      "Epoch 227/500: Train Loss = 1.9218, Test Loss = 1.9241\n",
      "Epoch 228/500: Train Loss = 1.9214, Test Loss = 1.9237\n",
      "Epoch 229/500: Train Loss = 1.9210, Test Loss = 1.9233\n",
      "Epoch 230/500: Train Loss = 1.9206, Test Loss = 1.9228\n",
      "Epoch 231/500: Train Loss = 1.9202, Test Loss = 1.9224\n",
      "Epoch 232/500: Train Loss = 1.9198, Test Loss = 1.9220\n",
      "Epoch 233/500: Train Loss = 1.9193, Test Loss = 1.9216\n",
      "Epoch 234/500: Train Loss = 1.9189, Test Loss = 1.9212\n",
      "Epoch 235/500: Train Loss = 1.9185, Test Loss = 1.9208\n",
      "Epoch 236/500: Train Loss = 1.9181, Test Loss = 1.9204\n",
      "Epoch 237/500: Train Loss = 1.9177, Test Loss = 1.9200\n",
      "Epoch 238/500: Train Loss = 1.9173, Test Loss = 1.9196\n",
      "Epoch 239/500: Train Loss = 1.9169, Test Loss = 1.9193\n",
      "Epoch 240/500: Train Loss = 1.9165, Test Loss = 1.9189\n",
      "Epoch 241/500: Train Loss = 1.9161, Test Loss = 1.9185\n",
      "Epoch 242/500: Train Loss = 1.9157, Test Loss = 1.9181\n",
      "Epoch 243/500: Train Loss = 1.9154, Test Loss = 1.9177\n",
      "Epoch 244/500: Train Loss = 1.9150, Test Loss = 1.9173\n",
      "Epoch 245/500: Train Loss = 1.9146, Test Loss = 1.9170\n",
      "Epoch 246/500: Train Loss = 1.9142, Test Loss = 1.9166\n",
      "Epoch 247/500: Train Loss = 1.9138, Test Loss = 1.9162\n",
      "Epoch 248/500: Train Loss = 1.9134, Test Loss = 1.9158\n",
      "Epoch 249/500: Train Loss = 1.9131, Test Loss = 1.9155\n",
      "Epoch 250/500: Train Loss = 1.9127, Test Loss = 1.9151\n",
      "Epoch 251/500: Train Loss = 1.9123, Test Loss = 1.9147\n",
      "Epoch 252/500: Train Loss = 1.9119, Test Loss = 1.9144\n",
      "Epoch 253/500: Train Loss = 1.9116, Test Loss = 1.9140\n",
      "Epoch 254/500: Train Loss = 1.9112, Test Loss = 1.9136\n",
      "Epoch 255/500: Train Loss = 1.9108, Test Loss = 1.9133\n",
      "Epoch 256/500: Train Loss = 1.9105, Test Loss = 1.9129\n",
      "Epoch 257/500: Train Loss = 1.9101, Test Loss = 1.9126\n",
      "Epoch 258/500: Train Loss = 1.9097, Test Loss = 1.9122\n",
      "Epoch 259/500: Train Loss = 1.9094, Test Loss = 1.9118\n",
      "Epoch 260/500: Train Loss = 1.9090, Test Loss = 1.9115\n",
      "Epoch 261/500: Train Loss = 1.9087, Test Loss = 1.9111\n",
      "Epoch 262/500: Train Loss = 1.9083, Test Loss = 1.9108\n",
      "Epoch 263/500: Train Loss = 1.9080, Test Loss = 1.9105\n",
      "Epoch 264/500: Train Loss = 1.9076, Test Loss = 1.9101\n",
      "Epoch 265/500: Train Loss = 1.9073, Test Loss = 1.9098\n",
      "Epoch 266/500: Train Loss = 1.9069, Test Loss = 1.9094\n",
      "Epoch 267/500: Train Loss = 1.9066, Test Loss = 1.9091\n",
      "Epoch 268/500: Train Loss = 1.9062, Test Loss = 1.9087\n",
      "Epoch 269/500: Train Loss = 1.9059, Test Loss = 1.9084\n",
      "Epoch 270/500: Train Loss = 1.9055, Test Loss = 1.9081\n",
      "Epoch 271/500: Train Loss = 1.9052, Test Loss = 1.9077\n",
      "Epoch 272/500: Train Loss = 1.9049, Test Loss = 1.9074\n",
      "Epoch 273/500: Train Loss = 1.9045, Test Loss = 1.9071\n",
      "Epoch 274/500: Train Loss = 1.9042, Test Loss = 1.9068\n",
      "Epoch 275/500: Train Loss = 1.9038, Test Loss = 1.9064\n",
      "Epoch 276/500: Train Loss = 1.9035, Test Loss = 1.9061\n",
      "Epoch 277/500: Train Loss = 1.9032, Test Loss = 1.9058\n",
      "Epoch 278/500: Train Loss = 1.9029, Test Loss = 1.9055\n",
      "Epoch 279/500: Train Loss = 1.9025, Test Loss = 1.9051\n",
      "Epoch 280/500: Train Loss = 1.9022, Test Loss = 1.9048\n",
      "Epoch 281/500: Train Loss = 1.9019, Test Loss = 1.9045\n",
      "Epoch 282/500: Train Loss = 1.9016, Test Loss = 1.9042\n",
      "Epoch 283/500: Train Loss = 1.9012, Test Loss = 1.9039\n",
      "Epoch 284/500: Train Loss = 1.9009, Test Loss = 1.9036\n",
      "Epoch 285/500: Train Loss = 1.9006, Test Loss = 1.9032\n",
      "Epoch 286/500: Train Loss = 1.9003, Test Loss = 1.9029\n",
      "Epoch 287/500: Train Loss = 1.9000, Test Loss = 1.9026\n",
      "Epoch 288/500: Train Loss = 1.8996, Test Loss = 1.9023\n",
      "Epoch 289/500: Train Loss = 1.8993, Test Loss = 1.9020\n",
      "Epoch 290/500: Train Loss = 1.8990, Test Loss = 1.9017\n",
      "Epoch 291/500: Train Loss = 1.8987, Test Loss = 1.9014\n",
      "Epoch 292/500: Train Loss = 1.8984, Test Loss = 1.9011\n",
      "Epoch 293/500: Train Loss = 1.8981, Test Loss = 1.9008\n",
      "Epoch 294/500: Train Loss = 1.8978, Test Loss = 1.9005\n",
      "Epoch 295/500: Train Loss = 1.8975, Test Loss = 1.9002\n",
      "Epoch 296/500: Train Loss = 1.8972, Test Loss = 1.8999\n",
      "Epoch 297/500: Train Loss = 1.8969, Test Loss = 1.8996\n",
      "Epoch 298/500: Train Loss = 1.8966, Test Loss = 1.8993\n",
      "Epoch 299/500: Train Loss = 1.8963, Test Loss = 1.8990\n",
      "Epoch 300/500: Train Loss = 1.8960, Test Loss = 1.8987\n",
      "Epoch 301/500: Train Loss = 1.8957, Test Loss = 1.8984\n",
      "Epoch 302/500: Train Loss = 1.8954, Test Loss = 1.8982\n",
      "Epoch 303/500: Train Loss = 1.8951, Test Loss = 1.8979\n",
      "Epoch 304/500: Train Loss = 1.8948, Test Loss = 1.8976\n",
      "Epoch 305/500: Train Loss = 1.8945, Test Loss = 1.8973\n",
      "Epoch 306/500: Train Loss = 1.8942, Test Loss = 1.8970\n",
      "Epoch 307/500: Train Loss = 1.8939, Test Loss = 1.8967\n",
      "Epoch 308/500: Train Loss = 1.8936, Test Loss = 1.8964\n",
      "Epoch 309/500: Train Loss = 1.8934, Test Loss = 1.8962\n",
      "Epoch 310/500: Train Loss = 1.8931, Test Loss = 1.8959\n",
      "Epoch 311/500: Train Loss = 1.8928, Test Loss = 1.8956\n",
      "Epoch 312/500: Train Loss = 1.8925, Test Loss = 1.8953\n",
      "Epoch 313/500: Train Loss = 1.8922, Test Loss = 1.8951\n",
      "Epoch 314/500: Train Loss = 1.8919, Test Loss = 1.8948\n",
      "Epoch 315/500: Train Loss = 1.8917, Test Loss = 1.8945\n",
      "Epoch 316/500: Train Loss = 1.8914, Test Loss = 1.8942\n",
      "Epoch 317/500: Train Loss = 1.8911, Test Loss = 1.8940\n",
      "Epoch 318/500: Train Loss = 1.8908, Test Loss = 1.8937\n",
      "Epoch 319/500: Train Loss = 1.8905, Test Loss = 1.8934\n",
      "Epoch 320/500: Train Loss = 1.8903, Test Loss = 1.8932\n",
      "Epoch 321/500: Train Loss = 1.8900, Test Loss = 1.8929\n",
      "Epoch 322/500: Train Loss = 1.8897, Test Loss = 1.8926\n",
      "Epoch 323/500: Train Loss = 1.8895, Test Loss = 1.8924\n",
      "Epoch 324/500: Train Loss = 1.8892, Test Loss = 1.8921\n",
      "Epoch 325/500: Train Loss = 1.8889, Test Loss = 1.8918\n",
      "Epoch 326/500: Train Loss = 1.8887, Test Loss = 1.8916\n",
      "Epoch 327/500: Train Loss = 1.8884, Test Loss = 1.8913\n",
      "Epoch 328/500: Train Loss = 1.8881, Test Loss = 1.8911\n",
      "Epoch 329/500: Train Loss = 1.8879, Test Loss = 1.8908\n",
      "Epoch 330/500: Train Loss = 1.8876, Test Loss = 1.8905\n",
      "Epoch 331/500: Train Loss = 1.8873, Test Loss = 1.8903\n",
      "Epoch 332/500: Train Loss = 1.8871, Test Loss = 1.8900\n",
      "Epoch 333/500: Train Loss = 1.8868, Test Loss = 1.8898\n",
      "Epoch 334/500: Train Loss = 1.8865, Test Loss = 1.8895\n",
      "Epoch 335/500: Train Loss = 1.8863, Test Loss = 1.8893\n",
      "Epoch 336/500: Train Loss = 1.8860, Test Loss = 1.8890\n",
      "Epoch 337/500: Train Loss = 1.8858, Test Loss = 1.8888\n",
      "Epoch 338/500: Train Loss = 1.8855, Test Loss = 1.8885\n",
      "Epoch 339/500: Train Loss = 1.8853, Test Loss = 1.8883\n",
      "Epoch 340/500: Train Loss = 1.8850, Test Loss = 1.8880\n",
      "Epoch 341/500: Train Loss = 1.8848, Test Loss = 1.8878\n",
      "Epoch 342/500: Train Loss = 1.8845, Test Loss = 1.8875\n",
      "Epoch 343/500: Train Loss = 1.8843, Test Loss = 1.8873\n",
      "Epoch 344/500: Train Loss = 1.8840, Test Loss = 1.8870\n",
      "Epoch 345/500: Train Loss = 1.8838, Test Loss = 1.8868\n",
      "Epoch 346/500: Train Loss = 1.8835, Test Loss = 1.8866\n",
      "Epoch 347/500: Train Loss = 1.8833, Test Loss = 1.8863\n",
      "Epoch 348/500: Train Loss = 1.8830, Test Loss = 1.8861\n",
      "Epoch 349/500: Train Loss = 1.8828, Test Loss = 1.8858\n",
      "Epoch 350/500: Train Loss = 1.8825, Test Loss = 1.8856\n",
      "Epoch 351/500: Train Loss = 1.8823, Test Loss = 1.8854\n",
      "Epoch 352/500: Train Loss = 1.8820, Test Loss = 1.8851\n",
      "Epoch 353/500: Train Loss = 1.8818, Test Loss = 1.8849\n",
      "Epoch 354/500: Train Loss = 1.8816, Test Loss = 1.8847\n",
      "Epoch 355/500: Train Loss = 1.8813, Test Loss = 1.8844\n",
      "Epoch 356/500: Train Loss = 1.8811, Test Loss = 1.8842\n",
      "Epoch 357/500: Train Loss = 1.8808, Test Loss = 1.8840\n",
      "Epoch 358/500: Train Loss = 1.8806, Test Loss = 1.8837\n",
      "Epoch 359/500: Train Loss = 1.8804, Test Loss = 1.8835\n",
      "Epoch 360/500: Train Loss = 1.8801, Test Loss = 1.8833\n",
      "Epoch 361/500: Train Loss = 1.8799, Test Loss = 1.8830\n",
      "Epoch 362/500: Train Loss = 1.8797, Test Loss = 1.8828\n",
      "Epoch 363/500: Train Loss = 1.8794, Test Loss = 1.8826\n",
      "Epoch 364/500: Train Loss = 1.8792, Test Loss = 1.8824\n",
      "Epoch 365/500: Train Loss = 1.8790, Test Loss = 1.8821\n",
      "Epoch 366/500: Train Loss = 1.8787, Test Loss = 1.8819\n",
      "Epoch 367/500: Train Loss = 1.8785, Test Loss = 1.8817\n",
      "Epoch 368/500: Train Loss = 1.8783, Test Loss = 1.8815\n",
      "Epoch 369/500: Train Loss = 1.8781, Test Loss = 1.8812\n",
      "Epoch 370/500: Train Loss = 1.8778, Test Loss = 1.8810\n",
      "Epoch 371/500: Train Loss = 1.8776, Test Loss = 1.8808\n",
      "Epoch 372/500: Train Loss = 1.8774, Test Loss = 1.8806\n",
      "Epoch 373/500: Train Loss = 1.8772, Test Loss = 1.8804\n",
      "Epoch 374/500: Train Loss = 1.8769, Test Loss = 1.8802\n",
      "Epoch 375/500: Train Loss = 1.8767, Test Loss = 1.8799\n",
      "Epoch 376/500: Train Loss = 1.8765, Test Loss = 1.8797\n",
      "Epoch 377/500: Train Loss = 1.8763, Test Loss = 1.8795\n",
      "Epoch 378/500: Train Loss = 1.8760, Test Loss = 1.8793\n",
      "Epoch 379/500: Train Loss = 1.8758, Test Loss = 1.8791\n",
      "Epoch 380/500: Train Loss = 1.8756, Test Loss = 1.8789\n",
      "Epoch 381/500: Train Loss = 1.8754, Test Loss = 1.8786\n",
      "Epoch 382/500: Train Loss = 1.8752, Test Loss = 1.8784\n",
      "Epoch 383/500: Train Loss = 1.8749, Test Loss = 1.8782\n",
      "Epoch 384/500: Train Loss = 1.8747, Test Loss = 1.8780\n",
      "Epoch 385/500: Train Loss = 1.8745, Test Loss = 1.8778\n",
      "Epoch 386/500: Train Loss = 1.8743, Test Loss = 1.8776\n",
      "Epoch 387/500: Train Loss = 1.8741, Test Loss = 1.8774\n",
      "Epoch 388/500: Train Loss = 1.8739, Test Loss = 1.8772\n",
      "Epoch 389/500: Train Loss = 1.8737, Test Loss = 1.8770\n",
      "Epoch 390/500: Train Loss = 1.8735, Test Loss = 1.8768\n",
      "Epoch 391/500: Train Loss = 1.8732, Test Loss = 1.8766\n",
      "Epoch 392/500: Train Loss = 1.8730, Test Loss = 1.8764\n",
      "Epoch 393/500: Train Loss = 1.8728, Test Loss = 1.8762\n",
      "Epoch 394/500: Train Loss = 1.8726, Test Loss = 1.8760\n",
      "Epoch 395/500: Train Loss = 1.8724, Test Loss = 1.8758\n",
      "Epoch 396/500: Train Loss = 1.8722, Test Loss = 1.8755\n",
      "Epoch 397/500: Train Loss = 1.8720, Test Loss = 1.8753\n",
      "Epoch 398/500: Train Loss = 1.8718, Test Loss = 1.8751\n",
      "Epoch 399/500: Train Loss = 1.8716, Test Loss = 1.8749\n",
      "Epoch 400/500: Train Loss = 1.8714, Test Loss = 1.8748\n",
      "Epoch 401/500: Train Loss = 1.8712, Test Loss = 1.8746\n",
      "Epoch 402/500: Train Loss = 1.8710, Test Loss = 1.8744\n",
      "Epoch 403/500: Train Loss = 1.8708, Test Loss = 1.8742\n",
      "Epoch 404/500: Train Loss = 1.8706, Test Loss = 1.8740\n",
      "Epoch 405/500: Train Loss = 1.8704, Test Loss = 1.8738\n",
      "Epoch 406/500: Train Loss = 1.8702, Test Loss = 1.8736\n",
      "Epoch 407/500: Train Loss = 1.8700, Test Loss = 1.8734\n",
      "Epoch 408/500: Train Loss = 1.8698, Test Loss = 1.8732\n",
      "Epoch 409/500: Train Loss = 1.8696, Test Loss = 1.8730\n",
      "Epoch 410/500: Train Loss = 1.8694, Test Loss = 1.8728\n",
      "Epoch 411/500: Train Loss = 1.8692, Test Loss = 1.8726\n",
      "Epoch 412/500: Train Loss = 1.8690, Test Loss = 1.8724\n",
      "Epoch 413/500: Train Loss = 1.8688, Test Loss = 1.8722\n",
      "Epoch 414/500: Train Loss = 1.8686, Test Loss = 1.8720\n",
      "Epoch 415/500: Train Loss = 1.8684, Test Loss = 1.8718\n",
      "Epoch 416/500: Train Loss = 1.8682, Test Loss = 1.8717\n",
      "Epoch 417/500: Train Loss = 1.8680, Test Loss = 1.8715\n",
      "Epoch 418/500: Train Loss = 1.8678, Test Loss = 1.8713\n",
      "Epoch 419/500: Train Loss = 1.8676, Test Loss = 1.8711\n",
      "Epoch 420/500: Train Loss = 1.8674, Test Loss = 1.8709\n",
      "Epoch 421/500: Train Loss = 1.8672, Test Loss = 1.8707\n",
      "Epoch 422/500: Train Loss = 1.8670, Test Loss = 1.8705\n",
      "Epoch 423/500: Train Loss = 1.8668, Test Loss = 1.8704\n",
      "Epoch 424/500: Train Loss = 1.8667, Test Loss = 1.8702\n",
      "Epoch 425/500: Train Loss = 1.8665, Test Loss = 1.8700\n",
      "Epoch 426/500: Train Loss = 1.8663, Test Loss = 1.8698\n",
      "Epoch 427/500: Train Loss = 1.8661, Test Loss = 1.8696\n",
      "Epoch 428/500: Train Loss = 1.8659, Test Loss = 1.8694\n",
      "Epoch 429/500: Train Loss = 1.8657, Test Loss = 1.8693\n",
      "Epoch 430/500: Train Loss = 1.8655, Test Loss = 1.8691\n",
      "Epoch 431/500: Train Loss = 1.8653, Test Loss = 1.8689\n",
      "Epoch 432/500: Train Loss = 1.8652, Test Loss = 1.8687\n",
      "Epoch 433/500: Train Loss = 1.8650, Test Loss = 1.8685\n",
      "Epoch 434/500: Train Loss = 1.8648, Test Loss = 1.8684\n",
      "Epoch 435/500: Train Loss = 1.8646, Test Loss = 1.8682\n",
      "Epoch 436/500: Train Loss = 1.8644, Test Loss = 1.8680\n",
      "Epoch 437/500: Train Loss = 1.8642, Test Loss = 1.8678\n",
      "Epoch 438/500: Train Loss = 1.8641, Test Loss = 1.8677\n",
      "Epoch 439/500: Train Loss = 1.8639, Test Loss = 1.8675\n",
      "Epoch 440/500: Train Loss = 1.8637, Test Loss = 1.8673\n",
      "Epoch 441/500: Train Loss = 1.8635, Test Loss = 1.8671\n",
      "Epoch 442/500: Train Loss = 1.8633, Test Loss = 1.8670\n",
      "Epoch 443/500: Train Loss = 1.8632, Test Loss = 1.8668\n",
      "Epoch 444/500: Train Loss = 1.8630, Test Loss = 1.8666\n",
      "Epoch 445/500: Train Loss = 1.8628, Test Loss = 1.8664\n",
      "Epoch 446/500: Train Loss = 1.8626, Test Loss = 1.8663\n",
      "Epoch 447/500: Train Loss = 1.8624, Test Loss = 1.8661\n",
      "Epoch 448/500: Train Loss = 1.8623, Test Loss = 1.8659\n",
      "Epoch 449/500: Train Loss = 1.8621, Test Loss = 1.8657\n",
      "Epoch 450/500: Train Loss = 1.8619, Test Loss = 1.8656\n",
      "Epoch 451/500: Train Loss = 1.8617, Test Loss = 1.8654\n",
      "Epoch 452/500: Train Loss = 1.8616, Test Loss = 1.8652\n",
      "Epoch 453/500: Train Loss = 1.8614, Test Loss = 1.8651\n",
      "Epoch 454/500: Train Loss = 1.8612, Test Loss = 1.8649\n",
      "Epoch 455/500: Train Loss = 1.8610, Test Loss = 1.8647\n",
      "Epoch 456/500: Train Loss = 1.8609, Test Loss = 1.8646\n",
      "Epoch 457/500: Train Loss = 1.8607, Test Loss = 1.8644\n",
      "Epoch 458/500: Train Loss = 1.8605, Test Loss = 1.8642\n",
      "Epoch 459/500: Train Loss = 1.8604, Test Loss = 1.8641\n",
      "Epoch 460/500: Train Loss = 1.8602, Test Loss = 1.8639\n",
      "Epoch 461/500: Train Loss = 1.8600, Test Loss = 1.8637\n",
      "Epoch 462/500: Train Loss = 1.8599, Test Loss = 1.8636\n",
      "Epoch 463/500: Train Loss = 1.8597, Test Loss = 1.8634\n",
      "Epoch 464/500: Train Loss = 1.8595, Test Loss = 1.8633\n",
      "Epoch 465/500: Train Loss = 1.8593, Test Loss = 1.8631\n",
      "Epoch 466/500: Train Loss = 1.8592, Test Loss = 1.8629\n",
      "Epoch 467/500: Train Loss = 1.8590, Test Loss = 1.8628\n",
      "Epoch 468/500: Train Loss = 1.8588, Test Loss = 1.8626\n",
      "Epoch 469/500: Train Loss = 1.8587, Test Loss = 1.8624\n",
      "Epoch 470/500: Train Loss = 1.8585, Test Loss = 1.8623\n",
      "Epoch 471/500: Train Loss = 1.8584, Test Loss = 1.8621\n",
      "Epoch 472/500: Train Loss = 1.8582, Test Loss = 1.8620\n",
      "Epoch 473/500: Train Loss = 1.8580, Test Loss = 1.8618\n",
      "Epoch 474/500: Train Loss = 1.8579, Test Loss = 1.8616\n",
      "Epoch 475/500: Train Loss = 1.8577, Test Loss = 1.8615\n",
      "Epoch 476/500: Train Loss = 1.8575, Test Loss = 1.8613\n",
      "Epoch 477/500: Train Loss = 1.8574, Test Loss = 1.8612\n",
      "Epoch 478/500: Train Loss = 1.8572, Test Loss = 1.8610\n",
      "Epoch 479/500: Train Loss = 1.8570, Test Loss = 1.8609\n",
      "Epoch 480/500: Train Loss = 1.8569, Test Loss = 1.8607\n",
      "Epoch 481/500: Train Loss = 1.8567, Test Loss = 1.8606\n",
      "Epoch 482/500: Train Loss = 1.8566, Test Loss = 1.8604\n",
      "Epoch 483/500: Train Loss = 1.8564, Test Loss = 1.8602\n",
      "Epoch 484/500: Train Loss = 1.8562, Test Loss = 1.8601\n",
      "Epoch 485/500: Train Loss = 1.8561, Test Loss = 1.8599\n",
      "Epoch 486/500: Train Loss = 1.8559, Test Loss = 1.8598\n",
      "Epoch 487/500: Train Loss = 1.8558, Test Loss = 1.8596\n",
      "Epoch 488/500: Train Loss = 1.8556, Test Loss = 1.8595\n",
      "Epoch 489/500: Train Loss = 1.8555, Test Loss = 1.8593\n",
      "Epoch 490/500: Train Loss = 1.8553, Test Loss = 1.8592\n",
      "Epoch 491/500: Train Loss = 1.8551, Test Loss = 1.8590\n",
      "Epoch 492/500: Train Loss = 1.8550, Test Loss = 1.8589\n",
      "Epoch 493/500: Train Loss = 1.8548, Test Loss = 1.8587\n",
      "Epoch 494/500: Train Loss = 1.8547, Test Loss = 1.8586\n",
      "Epoch 495/500: Train Loss = 1.8545, Test Loss = 1.8584\n",
      "Epoch 496/500: Train Loss = 1.8544, Test Loss = 1.8583\n",
      "Epoch 497/500: Train Loss = 1.8542, Test Loss = 1.8581\n",
      "Epoch 498/500: Train Loss = 1.8541, Test Loss = 1.8580\n",
      "Epoch 499/500: Train Loss = 1.8539, Test Loss = 1.8578\n",
      "Epoch 500/500: Train Loss = 1.8538, Test Loss = 1.8577\n",
      "Total runtime: 256.09 seconds\n"
     ]
    }
   ],
   "source": [
    "lr = logistic_regression(learning_rate=0.01, epochs=500)\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the LR model\n",
    "lr.fit(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# End timer and print elapsed time\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Total runtime: {elapsed_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Evaluation:\n",
      "Confusion Matrix:\n",
      " [[2273  317  169  144   91  144  148  268 1023  423]\n",
      " [ 324 1916   78  150  126  277  304  192  625 1008]\n",
      " [ 672  222 1060  294  628  512  809  359  293  151]\n",
      " [ 275  310  420  989  205 1220  643  317  286  335]\n",
      " [ 397  176  580  246 1364  527  891  458  177  184]\n",
      " [ 196  224  472  654  267 1877  543  341  250  176]\n",
      " [ 119  244  324  442  412  599 2252  264  135  209]\n",
      " [ 254  264  302  270  613  433  424 1714  217  509]\n",
      " [ 823  433   71   87   25  277   43   83 2584  574]\n",
      " [ 350  796   65  106   71  159  203  206  666 2378]]\n",
      "Accuracy: 0.3681\n",
      "Precision: 0.3633\n",
      "Recall: 0.3681\n",
      "F1 Score: 0.3657\n",
      "\n",
      "Validation Evaluation:\n",
      "Confusion Matrix:\n",
      " [[468  52  48  30  10  22  28  52 215  75]\n",
      " [ 73 392  15  34  22  64  66  33 133 168]\n",
      " [143  40 213  73 132 102 157  55  60  25]\n",
      " [ 54  70  93 200  38 248 113  71  51  62]\n",
      " [ 69  29 124  62 248 101 206  86  41  34]\n",
      " [ 32  35 108 120  55 371 120  76  61  22]\n",
      " [ 20  46  81  82  72 114 461  44  31  49]\n",
      " [ 53  59  66  50 118  85  62 343  49 115]\n",
      " [151 101  12  23   3  60   5  21 501 123]\n",
      " [ 79 146  10  28  18  26  48  38 141 466]]\n",
      "Accuracy: 0.3663\n",
      "Precision: 0.3615\n",
      "Recall: 0.3663\n",
      "F1 Score: 0.3639\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for train and test sets\n",
    "train_pred = lr.predict(X_train)\n",
    "\n",
    "# Calculate training metrics\n",
    "train_cm = confusion_matrix(y_train, train_pred)\n",
    "train_accuracy = accuracy(y_train, train_pred)\n",
    "train_precision = precision(train_cm)\n",
    "train_recall = recall(train_cm)\n",
    "train_f1 = f1_score(train_cm)\n",
    "\n",
    "# Print Metrics\n",
    "print(\"\\nTraining Evaluation:\")\n",
    "print(\"Confusion Matrix:\\n\", train_cm)\n",
    "print(f\"Accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Precision: {train_precision:.4f}\")\n",
    "print(f\"Recall: {train_recall:.4f}\")\n",
    "print(f\"F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "\n",
    "test_pred = lr.predict(X_test)\n",
    "\n",
    "test_cm = confusion_matrix(y_test, test_pred)\n",
    "test_accuracy = accuracy(y_test, test_pred)\n",
    "test_precision = precision(test_cm)\n",
    "test_recall = recall(test_cm)\n",
    "test_f1 = f1_score(test_cm)\n",
    "\n",
    "print(\"\\nValidation Evaluation:\")\n",
    "print(\"Confusion Matrix:\\n\", test_cm)\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot epoch vs log-loss\n",
    "epochs = list(range(1, len(lr.train_losses) + 1))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, lr.train_losses, label='Training Loss')\n",
    "plt.plot(epochs, lr.test_losses, label='Validation Loss')\n",
    "\n",
    "plt.title('Epoch vs Mean Log-Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Log-Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, learning_rate=0.01, lambda_param=0.01, n_epochs=10):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lambda_param = lambda_param\n",
    "        self.n_epochs = n_epochs\n",
    "        self.weights = None\n",
    "        self.accuracy_per_epoch = []\n",
    "\n",
    "    def fit(self, X, y, num_classes, x_test = None, y_test = None):\n",
    "        _, n_features = X.shape\n",
    "        self.weights = np.zeros((num_classes, n_features))\n",
    "        for epoch in range(self.n_epochs):\n",
    "            for c in range(num_classes):\n",
    "                y_binary = np.where(y == c, 1, -1)\n",
    "                w = self.weights[c,:]\n",
    "                \n",
    "                for idx, x_i in enumerate(X):\n",
    "                    condition = y_binary[idx] * (np.dot(x_i, w)) # Check if current sample passes margin condition\n",
    "                    if condition >= 1:\n",
    "                        w -= self.learning_rate * (2 * self.lambda_param * w)\n",
    "                    else:\n",
    "                        w -= self.learning_rate * (2 * self.lambda_param * w - x_i * y_binary[idx])\n",
    "                            \n",
    "                self.weights[c, :] = w\n",
    "            \n",
    "            # Evaluate after each epoch\n",
    "            if x_test is not None and y_test is not None:\n",
    "                y_pred = self.predict(x_test)\n",
    "                accuracy = np.mean(y_pred == y_test)\n",
    "                self.accuracy_per_epoch.append(accuracy)\n",
    "                print(f\"Epoch {epoch + 1}/{self.n_epochs} - Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    def predictProb(self, X):\n",
    "        linear_output = np.dot(X, self.weights.T)\n",
    "        return linear_output\n",
    "    \n",
    "    def predict(self, linear_output):\n",
    "        return np.argmax(self.predictProb(linear_output), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM...\n",
      "Epoch 1/20 - Accuracy: 32.25%\n",
      "Epoch 2/20 - Accuracy: 34.33%\n",
      "Epoch 3/20 - Accuracy: 35.26%\n",
      "Epoch 4/20 - Accuracy: 35.92%\n",
      "Epoch 5/20 - Accuracy: 36.02%\n",
      "Epoch 6/20 - Accuracy: 36.09%\n",
      "Epoch 7/20 - Accuracy: 36.62%\n",
      "Epoch 8/20 - Accuracy: 36.62%\n",
      "Epoch 9/20 - Accuracy: 36.76%\n",
      "Epoch 10/20 - Accuracy: 36.86%\n",
      "Epoch 11/20 - Accuracy: 36.96%\n",
      "Epoch 12/20 - Accuracy: 36.82%\n",
      "Epoch 13/20 - Accuracy: 37.12%\n",
      "Epoch 14/20 - Accuracy: 37.00%\n",
      "Epoch 15/20 - Accuracy: 37.08%\n",
      "Epoch 16/20 - Accuracy: 37.02%\n",
      "Epoch 17/20 - Accuracy: 37.15%\n",
      "Epoch 18/20 - Accuracy: 37.20%\n",
      "Epoch 19/20 - Accuracy: 37.14%\n",
      "Epoch 20/20 - Accuracy: 37.10%\n",
      "Total runtime: 86.92 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train the SVM\n",
    "print(\"Training SVM...\")\n",
    "svm = SVM(learning_rate=1e-5, lambda_param=0.1, n_epochs=20)\n",
    "\n",
    "# Decode labels from one-hot encoding to integers\n",
    "y_train_decoded = np.argmax(y_train, axis=1)\n",
    "y_test_decoded = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the SVM model\n",
    "svm.fit(X_train, y_train_decoded, num_classes, x_test=X_test, y_test=y_test_decoded)\n",
    "\n",
    "# End timer and print elapsed time\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Total runtime: {elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SVM...\n",
      "\n",
      "SVM Training Evaluation:\n",
      "Confusion Matrix:\n",
      " [[1535  361   20  616   25  101  112  311 1525  394]\n",
      " [ 112 2618    9  316   19  149  184  197  633  763]\n",
      " [ 329  327  345 1287  195  407  799  622  556  133]\n",
      " [ 125  435   65 2167   43  724  444  280  421  296]\n",
      " [ 190  244  164 1065  690  317  972  803  372  183]\n",
      " [  56  312  123 1569   83 1537  404  367  395  154]\n",
      " [  43  326   70 1289  152  308 2198  221  214  179]\n",
      " [  80  356   54  768  151  315  255 2243  335  443]\n",
      " [ 285  441    7  293    9  146   38   95 3233  453]\n",
      " [ 128 1009   12  254   11  111  149  195  765 2366]]\n",
      "Accuracy: 0.3786\n",
      "Precision: 0.4076\n",
      "Recall: 0.3786\n",
      "F1 Score: 0.3926\n",
      "\n",
      "SVM Validation Evaluation:\n",
      "Confusion Matrix:\n",
      " [[306  72   7 118   4  19  23  57 315  79]\n",
      " [ 26 494   3  68   3  33  35  40 146 152]\n",
      " [ 75  62  67 244  44  84 176 109 115  24]\n",
      " [ 24  84  17 431   7 154  88  56  72  67]\n",
      " [ 38  50  33 213 129  66 214 158  72  27]\n",
      " [ 15  57  24 292  20 306  78  88  93  27]\n",
      " [  4  69  17 256  25  52 465  33  42  37]\n",
      " [ 16  75   8 162  25  61  43 424  87  99]\n",
      " [ 55 101   0  66   1  31   9  19 628  90]\n",
      " [ 31 187   1  59   4  19  38  42 159 460]]\n",
      "Accuracy: 0.3710\n",
      "Precision: 0.3988\n",
      "Recall: 0.3710\n",
      "F1 Score: 0.3844\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Evaluating SVM...\")\n",
    "y_pred_train = svm.predict(X_train)\n",
    "y_pred_test = svm.predict(X_test)\n",
    "\n",
    "# Training Metrics\n",
    "train_cm_svm = confusion_matrix(y_train, y_pred_train)\n",
    "train_accuracy_svm = accuracy(y_train, y_pred_train)\n",
    "train_precision_svm = precision(train_cm_svm)\n",
    "train_recall_svm = recall(train_cm_svm)\n",
    "train_f1_svm = f1_score(train_cm_svm)\n",
    "\n",
    "print(\"\\nSVM Training Evaluation:\")\n",
    "print(\"Confusion Matrix:\\n\", train_cm_svm)\n",
    "print(f\"Accuracy: {train_accuracy_svm:.4f}\")\n",
    "print(f\"Precision: {train_precision_svm:.4f}\")\n",
    "print(f\"Recall: {train_recall_svm:.4f}\")\n",
    "print(f\"F1 Score: {train_f1_svm:.4f}\")\n",
    "\n",
    "# Test Metrics\n",
    "test_cm_svm = confusion_matrix(y_test, y_pred_test)\n",
    "test_accuracy_svm = accuracy(y_test, y_pred_test)\n",
    "test_precision_svm = precision(test_cm_svm)\n",
    "test_recall_svm = recall(test_cm_svm)\n",
    "test_f1_svm = f1_score(test_cm_svm)\n",
    "\n",
    "print(\"\\nSVM Validation Evaluation:\")\n",
    "print(\"Confusion Matrix:\\n\", test_cm_svm)\n",
    "print(f\"Accuracy: {test_accuracy_svm:.4f}\")\n",
    "print(f\"Precision: {test_precision_svm:.4f}\")\n",
    "print(f\"Recall: {test_recall_svm:.4f}\")\n",
    "print(f\"F1 Score: {test_f1_svm:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnsembleModel:\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "\n",
    "    def predictProb(self, X):\n",
    "        # Average probabilities from each model\n",
    "        probs = [model.predictProb(X) for model in self.models]\n",
    "        avg_probs = np.mean(probs, axis=0)\n",
    "        return avg_probs\n",
    "\n",
    "    def predict(self, X):\n",
    "        avg_probs = self.predictProb(X)\n",
    "        return np.argmax(avg_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = EnsembleModel(models=[lr, svm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble Training Evaluation:\n",
      "Confusion Matrix:\n",
      " [[1972  341   55  343   38  132  136  293 1270  420]\n",
      " [ 190 2349   23  225   43  205  223  202  635  905]\n",
      " [ 525  288  648  797  365  482  818  504  426  147]\n",
      " [ 178  380  172 1677   86  996  539  287  369  316]\n",
      " [ 300  214  314  658 1006  461  985  617  263  182]\n",
      " [ 111  257  244 1103  143 1808  474  359  332  169]\n",
      " [  85  271  136  878  248  457 2326  226  181  192]\n",
      " [ 143  321  128  530  325  407  323 2061  288  474]\n",
      " [ 526  435   27  168   10  218   42   95 2965  514]\n",
      " [ 228  922   25  170   29  143  171  192  726 2394]]\n",
      "Accuracy: 0.3841\n",
      "Precision: 0.3899\n",
      "Recall: 0.3841\n",
      "F1 Score: 0.3870\n",
      "\n",
      "Ensemble Validation Evaluation:\n",
      "Confusion Matrix:\n",
      " [[391  66  15  73   5  20  27  58 269  76]\n",
      " [ 46 453   7  42   8  54  49  35 144 162]\n",
      " [108  57 120 169  75 100 172  89  85  25]\n",
      " [ 29  81  42 330  17 207  93  69  68  64]\n",
      " [ 53  41  80 130 177  88 224 115  62  30]\n",
      " [ 26  43  54 209  31 355 100  85  75  22]\n",
      " [  7  61  37 176  37  77 482  37  37  49]\n",
      " [ 36  66  26  98  56  73  66 407  66 106]\n",
      " [ 93  97   2  41   2  47   7  20 584 107]\n",
      " [ 51 173   4  43   8  23  38  41 153 466]]\n",
      "Accuracy: 0.3765\n",
      "Precision: 0.3799\n",
      "Recall: 0.3765\n",
      "F1 Score: 0.3782\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Ensemble Model\n",
    "y_pred_train = ensemble.predict(X_train)\n",
    "y_pred_test = ensemble.predict(X_test)\n",
    "\n",
    "# Training Metrics\n",
    "train_cm_ensemble = confusion_matrix(y_train, y_pred_train)\n",
    "train_accuracy_ensemble = accuracy(y_train, y_pred_train)\n",
    "train_precision_ensemble = precision(train_cm_ensemble)\n",
    "train_recall_ensemble = recall(train_cm_ensemble)\n",
    "train_f1_ensemble = f1_score(train_cm_ensemble)\n",
    "\n",
    "print(\"\\nEnsemble Training Evaluation:\")\n",
    "print(\"Confusion Matrix:\\n\", train_cm_ensemble)\n",
    "print(f\"Accuracy: {train_accuracy_ensemble:.4f}\")\n",
    "print(f\"Precision: {train_precision_ensemble:.4f}\")\n",
    "print(f\"Recall: {train_recall_ensemble:.4f}\")\n",
    "print(f\"F1 Score: {train_f1_ensemble:.4f}\")\n",
    "\n",
    "# Test Metrics\n",
    "test_cm_ensemble = confusion_matrix(y_test, y_pred_test)\n",
    "test_accuracy_ensemble = accuracy(y_test, y_pred_test)\n",
    "test_precision_ensemble = precision(test_cm_ensemble)\n",
    "test_recall_ensemble = recall(test_cm_ensemble)\n",
    "test_f1_ensemble = f1_score(test_cm_ensemble)\n",
    "\n",
    "print(\"\\nEnsemble Validation Evaluation:\")\n",
    "print(\"Confusion Matrix:\\n\", test_cm_ensemble)\n",
    "print(f\"Accuracy: {test_accuracy_ensemble:.4f}\")\n",
    "print(f\"Precision: {test_precision_ensemble:.4f}\")\n",
    "print(f\"Recall: {test_recall_ensemble:.4f}\")\n",
    "print(f\"F1 Score: {test_f1_ensemble:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
